# ml-project
Rust-ML
یادگیری ماشینی یک مفهوم واقعا جالب در برنامه‌نویسی کامپیوتر است. این شامل استفاده از داده‌ها برای آموزش یک برنامه کامپیوتری برای انجام وظایف است.

در طول فرآیند، برنامه با کشف الگوها از داده‌ها یاد می‌گیرد. این امر نیاز برنامه‌نویسان را به قوانین کد سخت در برخی برنامه‌ها کاهش می‌دهد.

زبان‌هایی مانند پایتون و R برای یادگیری و انجام وظایف یادگیری ماشینی عالی هستند. اما آن زبان‌ها مطلق نیستند. آن‌ها نقاط ضعفی دارند. برخی از برنامه‌های کاربردی یادگیری ماشینی ممکن است نیاز به انجام عملیات با سرعت بالا و کارایی منابع رایانه داشته باشند. Rust یک زبان برنامه‌نویسی قدرتمند و کارآمد است. اگرچه Rust یک اکوسیستم بالغ ندارد، اما ماهیت زبان برنامه‌‌نویسی آن را برای برنامه‌هایی که نیاز به سرعت و کارایی دارند عالی می‌کند.

برنامه‌نویسان Rust این آموزش را برای شروع یادگیری ماشینی مفید خواهند یافت و مهندسان یادگیری ماشینی این آموزش را برای شروع یادگیری ماشینی در Rust مفید خواهند یافت.

پیش‌نیازها
برای دنبال کردن این آموزش به موارد زیر نیاز دارید:

دانش Rust
و Rust نصب شده در سیستم شما
یادگیری ماشینی چیست؟
در یادگیری ماشینی، یک مدل یک شی نرم‌افزاری است که می‌تواند الگوها را از داده‌ها درک کند. آموزش یک مدل، فرآیند دادن داده به مدل برای ترسیم الگوها است. یادگیری ماشینی فرآیند آموزش یک مدل برای انجام وظایف است.

هنگامی که مدل خود را آموزش دادید، می‌توانید از آن برای نتیجه‌گیری از داده‌های جدید استفاده کنید. شما می‌توانید آن نتایج را بر اساس طبقه‌بندی‌ها یا پیش‌بینی‌ها قرار دهید. یک مدل پیش‌بینی‌کننده از داده‌های فعلی برای پیش‌بینی یک رویداد یا نتیجه استفاده می‌کند. یک مدل طبقه‌بندی از داده‌ها برای طبقه‌بندی یک شی یا مفهوم استفاده می‌کند.

نمودار زیر یک نمای کلی از فرآیند یادگیری ماشینی است:

شکل ۱. نمای کلی از فرآیند یادگیری ماشینی
شکل ۱. نمای کلی از فرآیند یادگیری ماشینی
درخت تصمیم چیست؟
الگوریتم درخت تصمیم یکی از ساده ترین الگوریتم‌های یادگیری ماشینی است. این الگوریتم، برخلاف بسیاری از الگوریتم‌های دیگر، مفهوم واقعی یادگیری ماشینی را ارائه می‌دهد.

درخت تصمیم یک الگوریتم یادگیری ماشینی برای کارهای طبقه‌بندی و رگرسیون است. یک درخت تصمیم مانند یک درخت ساختاریافته است. دارای گره ریشه، گره داخلی، گره برگ و شاخه است.

جدول زیر نمونه‌ای از داده‌ها است که طبقه‌بندی چهار حیوان را با خواص آن‌ها نشان می‌دهد:


یک مدل الگو(های) جدول را تشخیص می‌دهد، سپس درختی با این ساختار ایجاد می‌کند:


گره ریشه اولین گره در درخت تصمیم است. گره‌های برگ در خط نهایی درخت تصمیم قرار دارند. گره‌های داخلی بین گره‌های ریشه و گره‌های برگ قرار دارند. یک درخت تصمیم می‌تواند بیش از یک لایه گره داخلی داشته باشد.

در این مقاله از این الگوریتم استفاده خواهیم کرد.

شروع
مجموعه ای از ابزارها وجود دارد که به شما امکان می دهد برنامه های یادگیری ماشینی را در Rust ایجاد کنید. همه ابزارها عالی هستند، اما برای این آموزش ازLinfa استفاده خواهید کرد. Linfa یک جعبه ابزار است که شبیه به ابزار یادگیری ماشینی محبوب Python scikit-learn است.

در این بخش، نحوه راه اندازی یک پروژه Rust برای یادگیری ماشینی را یاد خواهید گرفت. فرآیند راه‌اندازی یک پروژه نسبتاً ساده است. تنها کاری که باید انجام دهید این است که این مراحل را دنبال کنید:

ابتدا یک پروژه جدید به نامml-project با دستور زیر ایجاد کنید:

1
cargo new --bin ml-project
سپس، وابستگی‌های زیر را در فایلCargo.toml در ml-project، در زیر [وابستگی] قرار دهید:

1
linfa = &quot0.6.0&quot
1
linfa-trees = &quot0.6.0&quot
1
linfa-datasets = { version = &quot0.6.0&quot, features = [&quotiris&quot] }
در نهایت دستور زیر را برای ساخت وابستگی‌ها اجرا کنید:

1
cargo build
ساخت محموله
در زیر توضیحی در مورد وابستگی‌ها ارائه شده‌است:

جعبه ابزار linfa بسته پایه برای مدل‌های یادگیری ماشینیLinfa است.
جعبه ابزار linfa-trees یک بسته فرعی برای ساخت مدل‌های درخت تصمیم است.
جعبه ابزار linfa-datasets بسته‌ای است که مجموعه داده‌های از قبل آماده شده را ارائه می‌دهد.
بسته linfa-datasets اختیاری است. اگر می‌خواهید مجموعه داده خود را آماده کنید، بخش بعدی را دنبال کنید.

چگونه مجموعه داده را آماده کنیم؟
بیشتر مدل‌های یادگیری ماشینی که در پروژه‌های روزمره استفاده می‌شوند با داده‌های خارجی آموزش داده می‌شوند، نه داده‌های ارائه‌شده توسط جعبه ابزار. در این بخش، یاد خواهید گرفت که چگونه مجموعه داده خود را از یک فایل csv آماده کنید.

ابتدا، اگر مجموعه داده‌ای ندارید که بتوانید از آن استفاده کنید، باید یک مجموعه داده دریافت کنید. می‌توانید مجموعه داده‌ای را ازKaggle دریافت کنید. برای این آموزش، از مجموعه داده بیماری قلبی استفاده خواهم کرد. مجموعه داده‌های بیماری قلبی مانند زیر است:


در این مجموعه داده، هدف نشان می‌دهد که یک فرد بیماری قلبی دارد. ۱ به این معنی است که آن‌ها بیماری قلبی دارند، ۰ به این معنی است که آن‌ها بیماری قلبی ندارند.

بقیه فیلدهای مجموعه داده جزئیات هر فرد است. یک مدل می‌تواند از این مجموعه داده یاد بگیرد و بتواند تشخیص دهد که آیا یک فرد بیماری قلبی دارد یا خیر.

پس از دانلود مجموعه داده، فایل csv را در پوشه src پروژه خود استخراج کنید.

1
.
1
├── Cargo.lock
1
├── Cargo.toml
1
└── src
1
├── heart.csv
1
└── main.rs
1
برای تهیه یک مجموعه داده، باید بسته‌های csv وndarray را به پروژه خود اضافه کنید. Cargo.toml را باز کنید و عبارت پایین را زیر [وابستگی] بنویسید:

1
csv = &quot1.1&quot
1
ndarray = &quot0.15.6&quot
اکنون، کارگو بیلد را برای دانلود بسته‌ها اجرا کنید و آماده حرکت هستید.

در مراحل بعدی، من شما را در ساخت تابع get_dataset راهنمایی خواهم کرد. تابع get_dataset فایل heart.csv را می‌خواند، محتوای آن را تجزیه می‌کند، مجموعه داده‌ای را با محتوای آن آماده می‌کند و مجموعه داده آماده شده را برمی‌گرداند. بیا شروع کنیم!

ابتدا بسته‌های لازم را وارد کنید:

1
use csv::Reader;
1
use std::fs::File;
1
use ndarray::{ Array, Array1, Array2 };
1
use linfa::Dataset;
سپس تابع get_dataset زیر را در main.rs بنویسید:

1
fn get_dataset() -> Dataset<f32, i32, ndarray::Dim<[usize; 1]>> {
1
let mut reader = Reader::from_path(&quot./src/heart.csv&quot).unwrap();
1
1
let headers = get_headers(&mut reader);
1
let data = get_data(&mut reader);
1
let target_index = headers.len() - 1;
1
1
let features = headers[0..target_index].to_vec();
1
let records = get_records(&data, target_index);
1
let targets = get_targets(&data, target_index);
1
1
return Dataset::new(records, targets)
1
.with_feature_names(features);
1
}
در نهایت، با اضافه کردن تعاریف get_headers، get_data، get_records و get_targets کار را به پایان برسانید:

1
fn get_headers(reader: &mut Reader<File>) -> Vec<String> {
1
return reader
1
.headers().unwrap().iter()
1
.map(|r| r.to_owned())
1
.collect();
1
}
1
1
fn get_records(data: &Vec<Vec<f32>>, target_index: usize) -> Array2<f32> {
1
let mut records: Vec<f32> = vec![];
1
for record in data.iter() {
1
records.extend_from_slice( &record[0..target_index] );
1
}
1
return Array::from( records ).into_shape((303, 13)).unwrap();
1
}
1
1
fn get_targets(data: &Vec<Vec<f32>>, target_index: usize) -> Array1<i32> {
1
let targets = data
1
.iter()
1
.map(|record| record[target_index] as i32)
1
.collect::<Vec<i32>>();
1
return Array::from( targets );
1
}
1
1
fn get_data(reader: &mut Reader<File>) -> Vec<Vec<f32>> {
1
return reader
1
.records()
1
.map(|r|
1
r
1
.unwrap().iter()
1
.map(|field| field.parse::<f32>().unwrap())
1
.collect::<Vec<f32>>()
1
)
1
.collect::<Vec<Vec<f32>>>();
1
}
در اینجا توضیح گام‌به‌گام تابع get_dataset آمده‌است:

ابتدا، یک خواننده با اشاره به ./src/heart.csv مقداردهی اولیه کنید:

1
let mut reader = Reader::from_path(&quot./src/heart.csv&quot).unwrap();
در مرحله بعد، هدرها و داده‌ها را از خواننده استخراج کنید:

1
let headers = get_headers(&mut reader);
1
let data = get_data(&mut reader);
سپس، شاخص هدف را در هدرها محاسبه کنید:

1
let target_index = headers.len() - 1;
پس از آن، ویژگی‌ها را از هدرها دریافت کنید:

1
let features = headers[0..target_index].to_vec();
در مرحله بعد، سوابق و اهداف را از داده‌ها بازیابی کنید:

1
let records = get_records(&data, target_index);
1
let targets = get_targets(&data, target_index);
در نهایت، مجموعه داده را با رکوردها، اهداف و ویژگی‌ها بسازید، سپس برگردانید:

1
return Dataset::new(records, targets)
1
.with_feature_names(features);
برای تکمیل تابع و مشاهده اینکه چگونه مجموعه داده به نظر می‌رسد، تابع اصلی خود را به صورت زیر در نظر بگیرید:

1
fn main() {
1
let dataset = get_dataset();
1
println!(&quot{:?}&quot, dataset);
1
}
هنگامی که آن تابع اصلی خود را تعیین کردید و آن را با کارگو اجرا کردید، مجموعه داده را در خروجی مشاهده خواهید کرد:

1
DatasetBase { records: [[63.0, 1.0, 3.0, 145.0, 233.0, ..., 0.0, 2.3, 0.0, 0.0, 1.0],
1
[37.0, 1.0, 2.0, 130.0, 250.0, ..., 0.0, 3.5, 0.0, 0.0, 2.0],
1
[41.0, 0.0, 1.0, 130.0, 204.0, ..., 0.0, 1.4, 2.0, 0.0, 2.0],
1
[56.0, 1.0, 1.0, 120.0, 236.0, ..., 0.0, 0.8, 2.0, 0.0, 2.0],
1
[57.0, 0.0, 0.0, 120.0, 354.0, ..., 1.0, 0.6, 2.0, 0.0, 2.0],
1
...,
1
[57.0, 0.0, 0.0, 140.0, 241.0, ..., 1.0, 0.2, 1.0, 0.0, 3.0],
1
[45.0, 1.0, 3.0, 110.0, 264.0, ..., 0.0, 1.2, 1.0, 0.0, 3.0],
1
[68.0, 1.0, 0.0, 144.0, 193.0, ..., 0.0, 3.4, 1.0, 2.0, 3.0],
1
[57.0, 1.0, 0.0, 130.0, 131.0, ..., 1.0, 1.2, 1.0, 1.0, 3.0],
1
[57.0, 0.0, 1.0, 130.0, 236.0, ..., 0.0, 0.0, 1.0, 1.0, 2.0]], shape=[303, 13], strides=[13, 1], layout=Cc (0x5), const ndim=2, targets: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], shape=[303], strides=[1], layout=CFcf (0xf), const ndim=1, weights: [], shape=[0], strides=[0], layout=CFcf (0xf), const ndim=1, feature_names: [&quotage&quot, &quotsex&quot, &quotcp&quot, &quottrestbps&quot, &quotchol&quot, &quotfbs&quot, &quotrestecg&quot, &quotthalach&quot, &quotexang&quot, &quotoldpeak&quot, &quotslope&quot, &quotca&quot, &quotthal&quot] }
نحوه ایجاد یک مدل درخت تصمیم
در این بخش، نحوه ایجاد یک مدل درخت تصمیم و آموزش آن را به شما نشان خواهم داد. مجموعه داده‌ای که استفاده خواهم کرد مجموعه داده عنبیه ارائه شده توسط linfa-datasets است.

مجموعه داده عنبیه حاوی رکوردی از عرض کاسبرگ، ارتفاع کاسبرگ، عرض گلبرگ و ارتفاع گلبرگ چند عنبیه است و هر رکورد را بر اساس گونه‌های دارای برچسب شماره طبقه‌بندی می‌کند.

کد مدل ساده است. فایل main.rs را باز کنید و موارد زیر را در آن قرار دهید:

1
use linfa_trees::DecisionTree;
1
use linfa::prelude::*;
1
1
fn main() {
1
let (train, test) = linfa_datasets::iris()
1
.split_with_ratio(0.9);
1
1
let model = DecisionTree::params()
1
.fit(&train).unwrap();
1
1
let predictions = model.predict(&test);
1
1
println!(&quot{:?}&quot, predictions);
1
println!(&quot{:?}&quot, test.targets);
1
}
در اینجا یک توضیح است:

ابتدا بسته‌های لازم را وارد کنید:

1
use linfa_trees::DecisionTree;
1
use linfa::prelude::*;
سپس مجموعه داده را واکشی کنید و به داده‌های آزمایشی و آموزشی تقسیم کنید:

1
let (train, test) = linfa_datasets::iris()
1
.split_with_ratio(0.9);
پس از آن، مدل را مقداردهی اولیه کنید و آن را با داده‌های آموزشی آموزش دهید:

1
let model = DecisionTree::params()
1
.fit(&train).unwrap();
سپس، از داده‌های تست برای انجام برخی پیش‌بینی‌ها استفاده کنید:

1
let predictions = model.predict(&test);
در نهایت، پیش‌بینی‌ها را با مقادیر واقعی مقایسه کنید:

1
println!(&quot{:?}&quot, predictions);
1
println!(&quot{:?}&quot, test.targets);
اگر برنامه را با کارگو اجرا کنید، دسته پیش‌بینی شده و دسته واقعی در ترمینال را به‌عنوان خروجی دریافت خواهید کرد:

1
$ cargo run
1
[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], shape=[15], strides=[1], layout=CFcf (0xf), const ndim=1
1
[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], shape=[15], strides=[1], layout=CFcf (0xf), const ndim=1
با توجه به موارد فوق می‌توانید دقت کنید که این مدل ۱۰۰٪ است. این همیشه برای همه مدل‌های یادگیری ماشینی صدق نمی‌کند. اگر قبل از آموزش مدل در بالا، مجموعه داده را به هم بزنید، ممکن است مدل دیگر دقیق نباشد.

هدف یادگیری ماشینی این است که تا حد امکان دقیق باشد. اکثر اوقات دقت ۱۰۰٪ امکان‌پذیر نیست.

نتیجه‌گیری
در این آموزش کمی در مورد یادگیری ماشینی یاد گرفتید و هم‌چنین نحوه ایجاد یک مدل درخت تصمیم با استفاده از Rust را دیدید.

مدل‌های یادگیری ماشینی در لینفا از فرآیند مشابهی در ساخت و آموزش پیروی می‌کنند، بنابراین تنها کاری که برای استفاده از انواع دیگر مدل‌ها باید انجام دهید این است که در مورد هر یک از آن‌ها اطلاعات کسب کنید و می‌توانید ادامه دهید.
